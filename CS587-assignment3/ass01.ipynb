{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOD TO GO! Weights already downloaded and stored!\n"
     ]
    }
   ],
   "source": [
    "# DO THE FOLLOWING:\n",
    "# cd anaconda3 (or w./e your anaconda folder is called)\n",
    "# source bin/activate\n",
    "# conda create -n yourenvname python=3.5 anaconda\n",
    "# source activate yourenvname\n",
    "# conda install -n yourenvname -c conda-forge tensorflow=1.0\n",
    "# pip install pillow==4.0.0\n",
    "# pip install opencv-python==3.4.2.17\n",
    "# pip install tqdm \n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# # CS - 587 : Exercise 3a\n",
    "# ## Scope:\n",
    "# The goal of this assignment is to get familiar with fine-tunning in a new dataset a Convolutional Neural Network (CNN) that has been trained in another dataset, taking advantage of transfer learning.\n",
    "# \n",
    "# In your assignment you will be fine-tunning AlexNet a popular CNN architecture, that has been pretrained on ImageNet dataset. Your network will be finetuned for the task of recognizing art painting categories in a large dataset of art painting images, known as Wikiart.\n",
    "# \n",
    "# The WikiArt dataset, which consists of 4000 images of paintings of arbitrary sizes from 10 different styles - Baroque, Realism, Expressionism, etc.\n",
    "# \n",
    "# \n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_VLOG_LEVEL']='3'\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models.AlexNet import AlexNet\n",
    "from Utilities.datagenerator import ImageDataGenerator\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "#import urllib\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Configuration settings\n",
    "\"\"\"\n",
    "weight_path= os.path.join('weights','bvlc_alexnet.npy')\n",
    "general_path_weights = os.path.join('weights')\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(general_path_weights): \n",
    "    os.mkdir(general_path_weights)\n",
    "    \n",
    "def reporthook(blocknum, blocksize, totalsize):\n",
    "    readsofar = blocknum * blocksize\n",
    "    if totalsize > 0:\n",
    "        percent = readsofar * 1e2 / totalsize\n",
    "        s = \"\\r%5.1f%% %*d / %d\" % (\n",
    "            percent, len(str(totalsize)), readsofar, totalsize)\n",
    "        sys.stderr.write(s)\n",
    "        if readsofar >= totalsize: # near the end\n",
    "            sys.stderr.write(\"\\n\")\n",
    "    else: # total size is unknown\n",
    "        sys.stderr.write(\"read %d\\n\" % (readsofar,))   \n",
    "    \n",
    "if os.path.isfile(weight_path) == False:\n",
    "    print('Went to download weights for AlexNet, 230Mb from your disk will be put to good use! ')\n",
    "    print('Relax...')\n",
    "    weight_file = urllib.request.urlretrieve('http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/bvlc_alexnet.npy',\n",
    "                                             os.path.join('weights/bvlc_alexnet.npy'),\n",
    "                                             reporthook)\n",
    "    print('Done with weights!')\n",
    "else:\n",
    "    print('GOOD TO GO! Weights already downloaded and stored!')\n",
    "    \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Path to the textfiles for the trainings and validation set\n",
    "training_dirname = os.path.join('Utilities','data', 'train.txt')\n",
    "\n",
    "val_dirname = os.path.join('Utilities','data', 'test.txt')\n",
    "\n",
    "# Path for tf.summary.FileWriter and to store model checkpoints\n",
    "general_path = os.path.join('finetune_alexnet')\n",
    "filewriter_path = os.path.join('finetune_alexnet','wikiart')\n",
    "checkpoint_path = os.path.join('finetune_alexnet','CheckPoint')\n",
    "\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(general_path): \n",
    "    os.mkdir(general_path)\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(filewriter_path): os.mkdir(filewriter_path)\n",
    "# Create parent path if it doesn't exist\n",
    "if not os.path.isdir(checkpoint_path): os.mkdir(checkpoint_path)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Learning params\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Network params\n",
    "dropout_rate = 0.5\n",
    "num_classes = 10\n",
    "\n",
    "#---------------LOOK AT ME----------------------------------------------------\n",
    "\n",
    "train_layers = ['fc8', 'fc7'] # skip_layer : Change me if you want to try stuff\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# # Pretrained Model\n",
    "# For all of our image generation experiments, we will start with a convolutional neural network which was pretrained to perform image classification on ImageNet. We can use any model here, but for the purposes of this assignment we will use AlexNet\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# TF placeholder for graph input and output\n",
    "x = tf.placeholder(tf.float32, [batch_size, 227, 227, 3])\n",
    "y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Initialize model\n",
    "model = AlexNet(x, keep_prob, num_classes, train_layers)\n",
    "\n",
    "# List of trainable variables of the layers we want to train\n",
    "var_list = [v for v in tf.trainable_variables() if v.name.split('/')[0] in train_layers]\n",
    "\n",
    "# Link variable to model output\n",
    "score = model.fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<models.AlexNet.AlexNet at 0x7f5c3b06f4a8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################################################################\n",
    "# TODO: Implement the (a) losss function (Soft-max Cross Entropy), (b) the optimization        #\n",
    "# process using Gradient Descent, (c) accuracy (using argmax). Create summaries in tensorboard #\n",
    "# for the loss, the gradients of trainable variables (histogram form) and the accuracy.        #\n",
    "#                                                                                              # \n",
    "# Hint: in order to take the gradients per variable use tf.gradient(,)                         #\n",
    "# https://www.tensorflow.org/api_docs/python/tf/gradients  -> based on the loss                #\n",
    "################################################################################################    \n",
    "\n",
    "# define loss \n",
    "with tf.name_scope(\"cross_ent\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = score, labels = y))\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    # define gradients d(loss)/d(w), where w the weights in var_list\n",
    "    gradients = tf.gradients(loss, var_list) # graidents[0]: (4096,4096) weights of 'fc7'\n",
    "                                            # gradients[1]: (4096,) bias of 'fc7'\n",
    "                                            # gradients[2]: (4096,10) weights of 'fc8'\n",
    "                                            # gradients[3]: (10,) bias of 'fc8'\n",
    "    # reform gradients as list of tuples: \n",
    "    # [(gradients[0], 'fc7'), (gradients[1],'fc7'), (gradients[2],'fc8'), (gradients[3],'fc8')]\n",
    "    gradients = list(zip(gradients, var_list))\n",
    "\n",
    "    # define training optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars=gradients)\n",
    "    #train_op = optimizer.minimize(loss)\n",
    "\n",
    "# add the gradients-tuples of the variables we train to summary\n",
    "for grad, var in gradients:\n",
    "    tf.summary.histogram(var.name + '/gradient', grad)\n",
    "    \n",
    "# add the variables we train to the summary\n",
    "for var in var_list:\n",
    "    tf.summary.histogram(var.name, var)\n",
    "    \n",
    "# add loss to the summary\n",
    "tf.summary.scalar('cross_entropy', loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    # define accuracy\n",
    "    pred_correct = tf.equal(tf.argmax(score,1), tf.argmax(y,1))\n",
    "    pc_float32 = tf.cast(pred_correct, tf.float32)\n",
    "    accuracy = tf.reduce_mean(pc_float32)\n",
    "\n",
    "# add accuracy to summary\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "##############################################################################\n",
    "#                             END OF YOUR CODE                               #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tf.Tensor 'train/gradients/fc7/fc7/MatMul_grad/MatMul_1:0' shape=(4096, 4096) dtype=float32>,\n",
       "  <tensorflow.python.ops.variables.Variable at 0x7f5c6e94c2e8>),\n",
       " (<tf.Tensor 'train/gradients/fc7/fc7_grad/BiasAddGrad:0' shape=(4096,) dtype=float32>,\n",
       "  <tensorflow.python.ops.variables.Variable at 0x7f5c6e94c2b0>),\n",
       " (<tf.Tensor 'train/gradients/fc8/fc8/MatMul_grad/MatMul_1:0' shape=(4096, 10) dtype=float32>,\n",
       "  <tensorflow.python.ops.variables.Variable at 0x7f5c3acf79b0>),\n",
       " (<tf.Tensor 'train/gradients/fc8/fc8_grad/BiasAddGrad:0' shape=(10,) dtype=float32>,\n",
       "  <tensorflow.python.ops.variables.Variable at 0x7f5c3acf7978>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all summaries together\n",
    "merged_summary = tf.summary.merge_all()\n",
    "\n",
    "# Initialize the FileWriter\n",
    "writer = tf.summary.FileWriter(filewriter_path)\n",
    "\n",
    "# Initialize an saver for store model checkpoints\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Initalize the data generator seperately for the training and validation set\n",
    "train_generator = ImageDataGenerator(training_dirname, \n",
    "                                     horizontal_flip = True, \n",
    "                                     shuffle = True)\n",
    "val_generator = ImageDataGenerator(val_dirname, \n",
    "                                   shuffle = False) \n",
    "\n",
    "# Get the number of training/validation steps per epoch\n",
    "train_batches_per_epoch = np.floor(train_generator.data_size / batch_size).astype(np.int16)\n",
    "val_batches_per_epoch = np.floor(val_generator.data_size / batch_size).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 01:02:54.578121 Start training...\n",
      "2020-05-27 01:02:54.578211 Open Tensorboard at --logdir finetune_alexnet/wikiart\n",
      "2020-05-27 01:02:54.578240 Epoch number: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:41<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3333\n",
      "2020-05-27 01:06:02.157828 Saving checkpoint of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 01:06:05.562243 Model checkpoint saved at finetune_alexnet/CheckPoint/model_epoch1.ckpt\n",
      "2020-05-27 01:06:05.562323 Epoch number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3542\n",
      "2020-05-27 01:09:07.737180 Saving checkpoint of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 01:09:11.220043 Model checkpoint saved at finetune_alexnet/CheckPoint/model_epoch2.ckpt\n",
      "2020-05-27 01:09:11.220123 Epoch number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:36<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3529\n",
      "2020-05-27 01:12:14.043889 Saving checkpoint of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 01:12:17.618795 Model checkpoint saved at finetune_alexnet/CheckPoint/model_epoch3.ckpt\n",
      "2020-05-27 01:12:17.619006 Epoch number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:36<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3307\n",
      "2020-05-27 01:15:20.754179 Saving checkpoint of model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-27 01:15:24.386467 Model checkpoint saved at finetune_alexnet/CheckPoint/model_epoch4.ckpt\n",
      "2020-05-27 01:15:24.386757 Epoch number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:40<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.3802\n",
      "2020-05-27 01:18:31.993029 Saving checkpoint of model...\n",
      "2020-05-27 01:18:35.557945 Model checkpoint saved at finetune_alexnet/CheckPoint/model_epoch5.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Start Tensorflow session\n",
    "with tf.Session() as sess:\n",
    " \n",
    "    # Initialize all variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Add the model graph to TensorBoard\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    # Load the pretrained weights into the non-trainable layer\n",
    "    model.load_initial_weights(sess)\n",
    "\n",
    "    print(\"{} Start training...\".format(datetime.now()))\n",
    "    print(\"{} Open Tensorboard at --logdir {}\".format(datetime.now(), \n",
    "                                                filewriter_path))\n",
    "    \n",
    "    display_step = 3\n",
    "    # Loop over number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(\"{} Epoch number: {}\".format(datetime.now(), epoch+1))\n",
    "\n",
    "        step = 1\n",
    "\n",
    "        for step in tqdm(range(train_batches_per_epoch)):\n",
    "\n",
    "            # Get a batch of images and labels\n",
    "            batch_xs, batch_ys = train_generator.next_batch(batch_size)\n",
    "\n",
    "            ######################################################################################\n",
    "            #TODO: Run the training operation, print the current loss value write the symmaries.  #\n",
    "            #      The summarries must be written every 3 batches                                #\n",
    "            ######################################################################################\n",
    "\n",
    "            sess.run(train_op, feed_dict = {x: batch_xs, \n",
    "                                            y: batch_ys,\n",
    "                                            keep_prob: dropout_rate})\n",
    "            # every 3 batches generate summary with the current batch of data\n",
    "            if step%display_step == 0:\n",
    "                s = sess.run(merged_summary, feed_dict={x: batch_xs,\n",
    "                                                       y: batch_ys,\n",
    "                                                       keep_prob: 1.}) # keep all units, i.e. no dropout\n",
    "                writer.add_summary(s, epoch*train_batches_per_epoch + step)\n",
    "                \n",
    "            step += 1\n",
    "\n",
    "            #End of this task\n",
    "\n",
    "        ############################################################\n",
    "        #TODO: Validate the model on the ENTIRE validation set     #\n",
    "        #      Print the final validation accuracy of your model   #\n",
    "        ############################################################   \n",
    "        \n",
    "        test_acc = 0.\n",
    "        test_count = 0\n",
    "        \n",
    "        # for all validation batches\n",
    "        for _ in range(val_batches_per_epoch):\n",
    "            batch_tx, batch_ty = val_generator.next_batch(batch_size)\n",
    "            acc = sess.run(accuracy, feed_dict = {x: batch_tx,\n",
    "                                                  y: batch_ty,\n",
    "                                                  keep_prob: 1.}) # keep all units\n",
    "            test_acc += acc\n",
    "            test_count += 1\n",
    "        \n",
    "        test_acc /= test_count # mean accuracy for the validation set\n",
    "        #print(\"Validation Accuracy: {:, .4f}\".format(datetime.now(), test_acc))\n",
    "        print(\"Validation Accuracy: {:.4f}\".format(test_acc))\n",
    "\n",
    "        ##############################################################################\n",
    "        #                             END OF YOUR CODE                               #\n",
    "        ##############################################################################\n",
    "\n",
    "        # Reset the file pointer of the image data generator\n",
    "        val_generator.reset_pointer()\n",
    "        train_generator.reset_pointer()\n",
    "\n",
    "        print(\"{} Saving checkpoint of model...\".format(datetime.now()))  \n",
    "        \n",
    "\n",
    "        #save checkpoint of the model\n",
    "        checkpoint_name = os.path.join(checkpoint_path, 'model_epoch'+str(epoch+1)+'.ckpt')\n",
    "        save_path = saver.save(sess, checkpoint_name)  \n",
    "\n",
    "        print(\"{} Model checkpoint saved at {}\".format(datetime.now(), checkpoint_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEN A TERMINAL\n",
    "# cd anaconda3\n",
    "# source bin/acitvate\n",
    "# source activate youenvname\n",
    "# tensorboard --logdir=./finetune_alexnet/wikiart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35env",
   "language": "python",
   "name": "py35env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
